# Real Time Data Streaming Application
This service incorporates the following services Kafka, AWS EC2 instance, S3 bucket, Glue, Athena

## About the Dataset
The dataset used contains a list of video games with sales greater than 100,000 copies. It was generated by a scrape of vgchartz.com.
Fields include:

1) Rank - Ranking of overall sales

2) Name - The games name

3) Platform - Platform of the games release (i.e. PC,PS4, etc.)

4) Year - Year of the game's release

5) Genre - Genre of the game

6) Publisher - Publisher of the game

7) NA_Sales - Sales in North America (in millions)

8) EU_Sales - Sales in Europe (in millions)

9) JP_Sales - Sales in Japan (in millions)

10) Other_Sales - Sales in the rest of the world (in millions)

11) Global_Sales - Total worldwide sales.





































### Setting up Apache Kafka
#### Downloading Kafka
- wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz
- tar -xvf kafka_2.13-3.6.1.tgz

#### Installing Java
- java -version
- sudo apt install java-1.8.0-openjdk
- java -version

#### Start Zookeeper on console 1
- cd kafka_2.13-3.6.1
- bin/zookeeper-server-start.sh config/zookeeper.properties

#### Start Kafka Server on console 2
- export KAFKA_HEAP_OPTS="-Xmx256M -Xms128M" (Assigning memory to it)
- cd kafka_2.13-3.6.1
- bin/kafka-server-start.sh config/server.properties
- sudo nano config/server.properties (change ADVERTISED_LISTENERS to public ip of the ec2 instance)

#### Creating the Kafka Topic on console 3
- cd kafka_2.13-3.6.1
- bin/kafka-topics.sh --create --topic order_transactions --bootstrap-server {public_ip}:9092 --replication-factor 1 --partitions 1 
- bin/kafka-topics.sh --bootstrap-server {public_ip}:9092 --list (To verify topic creation successfull)

#### Starting the Kafka Producer
- cd kafka_2.13-3.6.1
- bin/kafka-console-producer.sh --topic order_transactions --bootstrap-server {public_ip}:9092

#### Starting the Kafka Consumer on console 4
- cd kafka_2.13-3.6.1
- bin/kafka-console-consumer.sh --topic order_transactions --bootstrap-server {public_ip}:9092

#### AWS Glue + Athena
- Setup AWS Glue crawler using the s3 bucket as it's data source, including a Glue IAM role with Administrator access
- Include/create a database to run with it
- Click on the newly created crawler & run it (This will create a schema in the new db using data from the datasource [s3 bucket])
- Go to Athena (Enables querying the created DB) & verify that the table has now been created & populated with the new data
NB: This crawler is to run only once to create the schema. Also when using Athena & error == `No output location provided. An output location is required either through the Workgroup result configuration setting or as an API input.` just allocate an s3 bucket to save the output.